{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from math import inf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def line_search_algo(phi, phi_deri=None, phi_ze=None,\n",
        "                         phi_old=None, phi_i=None,\n",
        "                         c1=1e-4, c2=0.9, alpha_max=inf):\n",
        "    \"\"\"Find alpha that satisfies strong Wolfe conditions.\n",
        "\n",
        "    alpha > 0 is assumed to be a  descent direction.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    phi : callable f(x,*args)\n",
        "        Objective scalar function.\n",
        "\n",
        "    derphi : callable f'(x,*args), optional\n",
        "        Objective function derivative (can be None)\n",
        "    phi0 : float, optional\n",
        "        Value of phi at s=0\n",
        "    old_phi0 : float, optional\n",
        "        Value of phi at previous point\n",
        "    derphi0 : float, optional\n",
        "        Value of derphi at s=0\n",
        "    args : tuple\n",
        "        Additional arguments passed to objective function.\n",
        "    c1 : float\n",
        "        Parameter for Armijo condition rule.\n",
        "    c2 : float\n",
        "        Parameter for curvature condition rule.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    alpha_star : float\n",
        "        Best alpha\n",
        "    phi_star\n",
        "        phi at alpha_star\n",
        "    phi0\n",
        "        phi at 0\n",
        "    derphi_star\n",
        "        derphi at alpha_star\n",
        "\n",
        "    the line search algorithm to enforce strong Wolfeconditions.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if phi_ze is None:\n",
        "        phi_ze = phi(0.)\n",
        "\n",
        "    if phi_i is None and phi_deri is not None:\n",
        "        phi_i = phi_deri(0.)\n",
        "\n",
        "    alpha0 = 0\n",
        "    if phi_old is not None:\n",
        "        alpha1 = min(1.0, 1.01*2*(phi_ze - phi_old)/phi_i)\n",
        "    else:\n",
        "        alpha1 = 1.0\n",
        "\n",
        "    if alpha1 < 0:\n",
        "        alpha1 = 1.0\n",
        "\n",
        "    if alpha1 == 0:\n",
        "        # useless while loop, and raise warnflag=2 due to possible imprecision.\n",
        "        alpha_new = None\n",
        "        phi_new = phi_ze\n",
        "        phi_ze = phi_old\n",
        "        phi_deri_new = None\n",
        "\n",
        "    phi_a1 = phi(alpha1)\n",
        "    #phi_deri_a1 = phi_deri(alpha1)  evaluated below\n",
        "\n",
        "    phi_a0 = phi_ze\n",
        "    phi_deri_a0 = phi_i\n",
        "\n",
        "    i = 1\n",
        "    maxiter = 10\n",
        "    for i in range(maxiter):\n",
        "        if alpha1 == 0:\n",
        "            break\n",
        "        if (phi_a1 > phi_ze + c1*alpha1*phi_i) or \\\n",
        "           ((phi_a1 >= phi_a0) and (i > 1)):\n",
        "            alpha_new, phi_new, phi_deri_new = \\\n",
        "                        zoom_algo(alpha0, alpha1, phi_a0,\n",
        "                              phi_a1, phi_deri_a0, phi, phi_deri,\n",
        "                              phi_ze, phi_i, c1, c2)\n",
        "            break\n",
        "\n",
        "        phi_deri_a1 = phi_deri(alpha1)\n",
        "        if (abs(phi_deri_a1) <= -c2*phi_i):\n",
        "            alpha_new = alpha1\n",
        "            phi_new = phi_a1\n",
        "            phi_deri_new = phi_deri_a1\n",
        "            break\n",
        "\n",
        "        if (phi_deri_a1 >= 0):\n",
        "            alpha_new, phi_new, phi_deri_new = \\\n",
        "                        zoom_algo(alpha1, alpha0, phi_a1,\n",
        "                              phi_a0, phi_deri_a1, phi, phi_deri,\n",
        "                              phi_ze, phi_i, c1, c2)\n",
        "            break\n",
        "        # increase by factor of two on each iteration\n",
        "        alpha2 = 2 * alpha1\n",
        "        i = i + 1\n",
        "        alpha0 = alpha1\n",
        "        alpha1 = alpha2\n",
        "        phi_a0 = phi_a1\n",
        "        phi_a1 = phi(alpha1)\n",
        "        phi_deri_a0 = phi_deri_a1\n",
        "\n",
        "    else:\n",
        "        # stopping test maxiter reached\n",
        "        alpha_new = alpha1\n",
        "        phi_new = phi_a1\n",
        "        phi_deri_new = None\n",
        "\n",
        "    return alpha_new, phi_new, phi_ze, phi_deri_new\n",
        "\n",
        "# cubic interlpolation function\n",
        "def cubic_interpolation (a,fa,fpa,b,fb,c,fc):\n",
        "\n",
        "    #Finds the minimizer for a cubic polynomial that goes through the\n",
        "    #points (a,fa), (b,fb), and (c,fc) with derivative at a of fpa.\n",
        "\n",
        "    #If no minimizer can be found return None\n",
        "\n",
        "    # f(x) = A *(x-a)^3 + B*(x-a)^2 + C*(x-a) + D\n",
        "\n",
        "    C = fpa\n",
        "    D = fa\n",
        "    db = b-a\n",
        "    dc = c-a\n",
        "    if (db == 0) or (dc == 0) or (b==c): return None\n",
        "    denom = (db*dc)**2 * (db-dc)\n",
        "    d1 = np.empty((2,2))\n",
        "    d1[0,0] = dc**2\n",
        "    d1[0,1] = -db**2\n",
        "    d1[1,0] = -dc**3\n",
        "    d1[1,1] = db**3\n",
        "    [A,B] = np.dot(d1, np.asarray([fb-fa-C*db,fc-fa-C*dc]).flatten())\n",
        "    A /= denom\n",
        "    B /= denom\n",
        "    radical = B*B-3*A*C\n",
        "    if radical < 0:  return None\n",
        "    if (A == 0): return None\n",
        "    xmin = a + (-B + np.sqrt(radical))/(3*A)\n",
        "    return xmin\n",
        "\n",
        "#quadratic interpolation function\n",
        "def quadratic_interpolation(a,fa,fpa,b,fb):\n",
        "\n",
        "    #Finds the minimizer for a quadratic polynomial that goes through\n",
        "    #the points (a,fa), (b,fb) with derivative at a of fpa,\n",
        "\n",
        "\n",
        "    # f(x) = B*(x-a)^2 + C*(x-a) + D\n",
        "    D = fa\n",
        "    C = fpa\n",
        "    db = b-a*1.0\n",
        "    if (db==0): return None\n",
        "    B = (fb-D-C*db)/(db*db)\n",
        "    if (B <= 0): return None\n",
        "    xmin = a  - C / (2.0*B)\n",
        "    return xmin\n",
        "\n",
        "# zoom algorithm according to Optimization book\n",
        "def zoom_algo(alpha_low, alpha_high, phi_lo, phi_hi, phi_deri_lo,\n",
        "          phi, phi_deri, phi_ze, phi_i, c1, c2):\n",
        "\n",
        "    maxiter = 10\n",
        "    i = 0\n",
        "    delta1 = 0.2  # cubic interpolant check\n",
        "    delta2 = 0.1  # quadratic interpolant check\n",
        "    phi_rec = phi_ze\n",
        "    a_rec = 0\n",
        "    while 1:\n",
        "        # interpolate to find a trial step length between alpha_low and\n",
        "        # alpha_high Need to choose interpolation here.  Use cubic\n",
        "        # interpolation and then if the result is within delta *\n",
        "        # dalpha or outside of the interval bounded by alpha_low or alpha_high\n",
        "        # then use quadratic interpolation, if the result is still too\n",
        "        # close, then use bisection\n",
        "\n",
        "        dalpha = alpha_high-alpha_low;\n",
        "        if dalpha < 0: a,b = alpha_high,alpha_low\n",
        "        else: a,b = alpha_low, alpha_high\n",
        "\n",
        "        # minimizer of cubic interpolant\n",
        "        # (uses phi_lo, phi_deri_lo, phi_hi, and the most recent value of phi)\n",
        "        #\n",
        "        # if the result is too close to the end points (or out of the\n",
        "        # interval) then use quadratic interpolation with phi_lo,\n",
        "        # phi_deri_lo and phi_hi if the result is stil too close to the\n",
        "        # end points (or out of the interval) then use bisection\n",
        "\n",
        "        if (i > 0):\n",
        "            cchk = delta1*dalpha\n",
        "            a_j = cubic_interpolation (alpha_low, phi_lo, phi_deri_lo, alpha_high, phi_hi, a_rec, phi_rec)\n",
        "        if (i==0) or (a_j is None) or (a_j > b-cchk) or (a_j < a+cchk):\n",
        "            qchk = delta2*dalpha\n",
        "            a_j = quadratic_interpolation(alpha_low, phi_lo, phi_deri_lo, alpha_high, phi_hi)\n",
        "            if (a_j is None) or (a_j > b-qchk) or (a_j < a+qchk):\n",
        "                a_j = alpha_low + 0.5*dalpha\n",
        "\n",
        "        # Check new value of a_j\n",
        "\n",
        "        phi_aj = phi(a_j)\n",
        "        if (phi_aj > phi_ze + c1*a_j*phi_i) or (phi_aj >= phi_lo):\n",
        "            phi_rec = phi_hi\n",
        "            a_rec = alpha_high\n",
        "            alpha_high = a_j\n",
        "            phi_hi = phi_aj\n",
        "        else:\n",
        "            phi_deri_aj = phi_deri(a_j)\n",
        "            if abs(phi_deri_aj) <= -c2*phi_i:\n",
        "                a_star = a_j\n",
        "                val_star = phi_aj\n",
        "                valprime_star = phi_deri_aj\n",
        "                break\n",
        "            if phi_deri_aj*(alpha_high - alpha_low) >= 0:\n",
        "                phi_rec = phi_hi\n",
        "                a_rec = alpha_high\n",
        "                alpha_high = alpha_low\n",
        "                phi_hi = phi_lo\n",
        "            else:\n",
        "                phi_rec = phi_lo\n",
        "                a_rec = alpha_low\n",
        "            alpha_low = a_j\n",
        "            phi_lo = phi_aj\n",
        "            phi_deri_lo = phi_deri_aj\n",
        "        i += 1\n",
        "        if (i > maxiter):\n",
        "            a_star = a_j\n",
        "            val_star = phi_aj\n",
        "            valprime_star = None\n",
        "            break\n",
        "    return a_star, val_star, valprime_star\n"
      ],
      "metadata": {
        "id": "Rx-U9dBv_pmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "def steepest_descent_line_search(objective, initial_point, alpha, beta, gamma, max_iterations=100, tol=1e-6):\n",
        "    x = np.array(initial_point)\n",
        "    history = [x]\n",
        "\n",
        "    for k in range(max_iterations):\n",
        "        gradient = approximate_gradient(objective, x)\n",
        "        norm_gradient = np.linalg.norm(gradient)\n",
        "\n",
        "        if norm_gradient < tol:\n",
        "            break\n",
        "\n",
        "        # Step (a): Choose a descent direction\n",
        "        descent_direction = -gradient\n",
        "\n",
        "        # Step (b): Line search to find the step size lambda\n",
        "        def phi(alpha):\n",
        "            return objective(x + alpha * descent_direction)\n",
        "\n",
        "        def phi_deri(alpha):\n",
        "            return np.dot(approximate_gradient(objective, x + alpha * descent_direction), descent_direction)\n",
        "\n",
        "        alpha_new, _, _, _ = line_search_algo(phi, phi_deri, c1=alpha, c2=beta)\n",
        "\n",
        "        # Update x\n",
        "        x = x + alpha_new * descent_direction\n",
        "        history.append(x)\n",
        "\n",
        "    return x, objective(x), history\n",
        "#gradient algo\n",
        "def approximate_gradient(objective, x, epsilon=1e-6):\n",
        "    n = len(x)\n",
        "    gradient = np.zeros(n)\n",
        "\n",
        "    for i in range(n):\n",
        "        perturbed_x1 = x.copy()\n",
        "        perturbed_x2 = x.copy()\n",
        "        perturbed_x1[i] += epsilon\n",
        "        perturbed_x2[i] -= epsilon\n",
        "\n",
        "        gradient[i] = (objective(perturbed_x1) - objective(perturbed_x2)) / (2 * epsilon)\n",
        "\n",
        "    return gradient\n",
        "\n",
        "# Examples\n",
        "def objective_function1(x):\n",
        "    return x[0]**4 + x[0]**2 + x[1]**2\n",
        "\n",
        "initial_points = [(0, 0), (1, 0), (0, 1)]\n",
        "# alpha,beta,gamma parameter\n",
        "alpha = 1e-4\n",
        "beta = 0.9\n",
        "gamma = 0.1\n",
        "\n",
        "for initial_point in initial_points:\n",
        "    result, min_value, history = steepest_descent_line_search(objective_function1, initial_point, alpha, beta, gamma)\n",
        "    print(f\"function 1: Initial Point : {initial_point}, Minimum: {result}, Min Value: {min_value}, Iterations: {len(history)}\")\n",
        "\n",
        "# Example 2\n",
        "def objective_function2(x):\n",
        "    return 10 * (x[1] - x[0]**2) + (1 - x[0])**2\n",
        "def objective_function3(w):\n",
        "    lam = 1\n",
        "    result = (\n",
        "        0.5 * lam * (w[0] * w[0] + w[1] * w[1] + w[2] * w[2]) +\n",
        "        np.log(1 + np.exp(-(w[0] + w[1] * 2.0 + w[2]))) +\n",
        "        np.log(1 + np.exp(-(w[0] * 2.0 + w[1] * 4.0 + w[2]))) +\n",
        "        np.log(1 + np.exp(-(w[0] * 2.5 + w[1] * 3.5 + w[2]))) +\n",
        "        np.log(1 + np.exp(-(w[0] * 3.0 + w[1] * 1.5 + w[2]))) +\n",
        "        np.log(1 + np.exp(-(w[0] * 3.5 + w[1] * 4.5 + w[2]))) +\n",
        "        np.log(1 + np.exp((w[0] * 4 + w[1] * 1.5 + w[2]))) +\n",
        "        np.log(1 + np.exp((w[0] * 4 + w[1] * 3.5 + w[2]))) +\n",
        "        np.log(1 + np.exp((w[0] * 4.5 + w[1] * 2.5 + w[2]))) +\n",
        "        np.log(1 + np.exp((w[0] * 5 + w[1] + w[2]))) +\n",
        "        np.log(1 + np.exp((w[0] * 6 + w[1] * 2 + w[2]))) +\n",
        "        np.log(1 + np.exp(-(w[0] * 6.5 + w[1] * 3 + w[2]))) +\n",
        "        np.log(1 + np.exp((w[0] * 7 + w[1] * 1.5 + w[2])))\n",
        "    )\n",
        "    return result\n",
        "    return result\n",
        "\n",
        "\n",
        "initial_points = [(0, 0), (1, 0), (0, 1)]\n",
        "\n",
        "for initial_point in initial_points:\n",
        "    result, min_value, history = steepest_descent_line_search(objective_function2, initial_point, alpha, beta, gamma)\n",
        "    print(f\"function 2: Initial Point: {initial_point}, Minimum: {result}, Min Value: {min_value}, Iterations: {len(history)}\")\n",
        "initial_points1 = [(0, 0, 0), (1, 0, 0), (0, 1, 0), (0, 0, 1)]\n",
        "\n",
        "for initial_point in initial_points1:\n",
        "    result, min_value, history = steepest_descent_line_search(objective_function3, initial_point, alpha, beta, gamma)\n",
        "    print(f\"Objective 3: Initial Point: {initial_point}, Minimum: {result}, Min Value: {min_value}, Iterations: {len(history)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LbilFLF_wDp",
        "outputId": "a78d8458-3848-48a2-949a-3cc1970b3cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "function 1: Initial Point : (0, 0), Minimum: [0 0], Min Value: 0, Iterations: 1\n",
            "function 1: Initial Point : (1, 0), Minimum: [3.33603769e+21 0.00000000e+00], Min Value: 1.2385792282542147e+86, Iterations: 5\n",
            "function 1: Initial Point : (0, 1), Minimum: [0.00000000e+00 2.84217094e-14], Min Value: 8.077935669463161e-28, Iterations: 3\n",
            "function 2: Initial Point: (0, 0), Minimum: [0 0], Min Value: 1, Iterations: 1\n",
            "function 2: Initial Point: (1, 0), Minimum: [1.36704e+11 0.00000e+00], Min Value: -1.6819185254673408e+23, Iterations: 3\n",
            "function 2: Initial Point: (0, 1), Minimum: [ 2.08080078e+10 -2.56001562e+09], Min Value: -3.8967587021927654e+21, Iterations: 5\n",
            "Objective 3: Initial Point: (0, 0, 0), Minimum: [0 0 0], Min Value: 8.317766166719343, Iterations: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-f06a7d47c05e>:67: RuntimeWarning: overflow encountered in exp\n",
            "  np.log(1 + np.exp(-(w[0] + w[1] * 2.0 + w[2]))) +\n",
            "<ipython-input-49-f06a7d47c05e>:68: RuntimeWarning: overflow encountered in exp\n",
            "  np.log(1 + np.exp(-(w[0] * 2.0 + w[1] * 4.0 + w[2]))) +\n",
            "<ipython-input-49-f06a7d47c05e>:69: RuntimeWarning: overflow encountered in exp\n",
            "  np.log(1 + np.exp(-(w[0] * 2.5 + w[1] * 3.5 + w[2]))) +\n",
            "<ipython-input-49-f06a7d47c05e>:70: RuntimeWarning: overflow encountered in exp\n",
            "  np.log(1 + np.exp(-(w[0] * 3.0 + w[1] * 1.5 + w[2]))) +\n",
            "<ipython-input-49-f06a7d47c05e>:71: RuntimeWarning: overflow encountered in exp\n",
            "  np.log(1 + np.exp(-(w[0] * 3.5 + w[1] * 4.5 + w[2]))) +\n",
            "<ipython-input-49-f06a7d47c05e>:77: RuntimeWarning: overflow encountered in exp\n",
            "  np.log(1 + np.exp(-(w[0] * 6.5 + w[1] * 3 + w[2]))) +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Objective 3: Initial Point: (1, 0, 0), Minimum: [nan nan nan], Min Value: nan, Iterations: 101\n",
            "Objective 3: Initial Point: (0, 1, 0), Minimum: [nan nan nan], Min Value: nan, Iterations: 101\n",
            "Objective 3: Initial Point: (0, 0, 1), Minimum: [nan nan nan], Min Value: nan, Iterations: 101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reference \"https://github.com/minrk/scipy-1/blob/master/scipy/optimize/linesearch.py\"\n"
      ],
      "metadata": {
        "id": "MHC8LsCD2Gk_"
      }
    }
  ]
}